{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv('weather.csv')\n",
        "\n",
        "#rain\n",
        "non_missing_rain = df['rain'].dropna()\n",
        "\n",
        "rain_mean = non_missing_rain.mean()\n",
        "rain_std = non_missing_rain.std()\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "for idx, row in df.iterrows():\n",
        "    if pd.isna(row['rain']):\n",
        "        imputed_rain = np.random.normal(loc=rain_mean, scale=rain_std)\n",
        "        imputed_rain = np.clip(imputed_rain, 0, 1)\n",
        "        imputed_rain = round(imputed_rain, 4)\n",
        "        df.at[idx, 'rain'] = imputed_rain\n",
        "\n",
        "\n",
        "def impute_column_with_random_values(column_name):\n",
        "    col_min = df[column_name].min()\n",
        "    col_max = df[column_name].max()\n",
        "\n",
        "    non_missing_values = df[column_name].dropna()\n",
        "\n",
        "    np.random.seed(42)\n",
        "    for idx, row in df.iterrows():\n",
        "        if pd.isna(row[column_name]):\n",
        "            imputed_value = np.random.uniform(low=col_min, high=col_max)\n",
        "            imputed_value = round(imputed_value, 2)\n",
        "            df.at[idx, column_name] = imputed_value\n",
        "\n",
        "columns_to_impute = ['temp','clouds', 'pressure', 'humidity', 'wind']\n",
        "\n",
        "\n",
        "for column in columns_to_impute:\n",
        "    impute_column_with_random_values(column)\n",
        "\n",
        "\n",
        "df.to_csv('updated_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "9NyIvrTAeGzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "df = pd.read_csv('updated_dataset.csv')\n",
        "\n",
        "\n",
        "columns_to_normalize = ['temp', 'pressure', 'rain', 'humidity', 'wind']\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "\n",
        "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
        "\n",
        "\n",
        "df[columns_to_normalize] = df[columns_to_normalize].round(4)\n",
        "\n",
        "\n",
        "df.to_csv('normalized_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "1UJlanbNe-7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your normalized dataset into a pandas DataFrame\n",
        "df = pd.read_csv('normalized_dataset.csv')\n",
        "\n",
        "# Define weighted coefficients for each weather feature\n",
        "w_temp = 0.3\n",
        "w_pressure = 0.2\n",
        "w_rain = 0.4\n",
        "w_humidity = 0.1\n",
        "w_clouds = 0.3\n",
        "w_wind = 0.2\n",
        "\n",
        "# Calculate surge factor (SF) using the adjusted formula\n",
        "df['surge_factor'] = (1 + (\n",
        "    w_temp * df['temp'] +\n",
        "    w_clouds * df['clouds'] +\n",
        "    w_pressure * df['pressure'] +\n",
        "    w_rain * df['rain'] +\n",
        "    w_humidity * df['humidity'] +\n",
        "    w_wind * df['wind']\n",
        ") / 2).round(4)\n",
        "\n",
        "# Clip surge factor to ensure it falls within the range [1, 2]\n",
        "df['surge_factor'] = df['surge_factor'].clip(lower=1, upper=2)\n",
        "\n",
        "# Save the DataFrame with surge factor as an extra column to a new CSV file\n",
        "df.to_csv('finalweather.csv', index=False)\n",
        "\n",
        "# Print message indicating successful save\n",
        "print(\"DataFrame with surge factor saved to FINALWEATHER.csv\")\n"
      ],
      "metadata": {
        "id": "Ep27mtDDk_yf",
        "outputId": "aa53b819-c209-4fc2-9c37-bf82c4d38b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with surge factor saved to FINALWEATHER.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv1_path = 'dynamic.csv'\n",
        "csv2_path = 'finalweather.csv'\n",
        "\n",
        "df1 = pd.read_csv(csv1_path)\n",
        "df2 = pd.read_csv(csv2_path)\n",
        "\n",
        "# Determine the number of times df1 rows need to be repeated\n",
        "repeat_factor = (len(df2) // len(df1)) + 1  # Ensure enough repeats to cover df2\n",
        "\n",
        "# Repeat rows of df1 to match the length of df2\n",
        "df1_repeated = pd.concat([df1] * repeat_factor, ignore_index=True).iloc[:len(df2)]\n",
        "\n",
        "# Concatenate df1_repeated with df2\n",
        "combined_df = pd.concat([df1_repeated, df2], axis=1)\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file\n",
        "output_file_path = 'combineddf1df2.csv'\n",
        "combined_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f'Saved combined data to: {output_file_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyE_ImJUCn3M",
        "outputId": "e44119b3-31a0-4def-bf48-c7c06f1bf921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved combined data to: combineddf1df2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V3Jgo_DZLCiP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}